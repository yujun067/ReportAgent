# ollama 项目进展

## 时间周期：2025-05-27至2025-05-28

## 新增功能
- 客户端新增请求签名功能以增强请求安全性。
- 更新学习模型以符合标准的安全指导方针，提升整体安全性。

## 主要改进
- 优化kvcache，跳过计算因最坏情况图保留而产生的因果掩码。
- 增强Docker镜像支持Intel GPU加速，与NVIDIA的兼容性进行评估。

## 修复问题
- 修复了因内存管理不当导致的gemma EOF错误。
- 解决了Ollama在检测到GPU时无法在其上运行模型的问题。
- 修复了Ollama 0.6.6版本中不同模型引起的内存泄漏问题。
- 修复了在加载模型时由于CUDA缓冲区分配失败导致的错误。
- 修复了Llama 3在GPU上运行快速，同时Llama 2在CPU上运行缓慢的问题。
- 修复了OllamaLLM对象缺少'__pydantic_private__'属性的错误。
- 针对安全漏洞CVE-2025-1975进行了修复。